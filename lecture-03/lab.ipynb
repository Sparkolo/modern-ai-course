{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hFgoWb-cQTFe"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/real-itu/modern-ai-course/blob/master/lecture-03/lab.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WCsnF20ssl92"
   },
   "source": [
    "# Lab 3 - Monte Carlo Tree Search\n",
    "\n",
    "In this exercise we will use the same game as in the previous exercise, namely, Connect 4.\n",
    "([Connect 4](https://en.wikipedia.org/wiki/Connect_Four)). You should implement the MCTS algorithm to play the game."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j6HUcMYbuEq_"
   },
   "source": [
    "As before, the game is implemented below. It will play a game where both players take random (legal) actions. The MAX player is represented with a X and the MIN player with an O. The MAX player starts. Execute the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-jWBNC6j1O91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  1  2  3  4  5  6\n",
      ".  .  .  .  .  .  .\n",
      ".  .  .  .  .  .  .\n",
      ".  .  .  .  .  .  .\n",
      ".  .  .  .  .  .  .\n",
      ".  .  .  .  .  .  .\n",
      "X  .  .  .  .  .  .\n",
      "\n",
      "0  1  2  3  4  5  6\n",
      ".  .  .  .  .  .  .\n",
      ".  .  .  .  .  .  .\n",
      ".  .  .  .  .  .  .\n",
      ".  .  .  .  .  .  .\n",
      "O  .  .  .  .  .  .\n",
      "X  .  .  .  .  .  .\n",
      "\n",
      "0  1  2  3  4  5  6\n",
      ".  .  .  .  .  .  .\n",
      ".  .  .  .  .  .  .\n",
      ".  .  .  .  .  .  .\n",
      ".  .  .  .  .  .  .\n",
      "O  .  .  .  .  .  .\n",
      "X  .  .  .  X  .  .\n",
      "\n",
      "0  1  2  3  4  5  6\n",
      ".  .  .  .  .  .  .\n",
      ".  .  .  .  .  .  .\n",
      ".  .  .  .  .  .  .\n",
      ".  .  .  .  .  .  .\n",
      "O  .  .  .  .  .  .\n",
      "X  O  .  .  X  .  .\n",
      "\n",
      "0  1  2  3  4  5  6\n",
      ".  .  .  .  .  .  .\n",
      ".  .  .  .  .  .  .\n",
      ".  .  .  .  .  .  .\n",
      ".  .  .  .  .  .  .\n",
      "O  .  .  .  .  .  .\n",
      "X  O  X  .  X  .  .\n",
      "\n",
      "0  1  2  3  4  5  6\n",
      ".  .  .  .  .  .  .\n",
      ".  .  .  .  .  .  .\n",
      ".  .  .  .  .  .  .\n",
      ".  .  .  .  .  .  .\n",
      "O  .  .  .  .  .  .\n",
      "X  O  X  O  X  .  .\n",
      "\n",
      "0  1  2  3  4  5  6\n",
      ".  .  .  .  .  .  .\n",
      ".  .  .  .  .  .  .\n",
      ".  .  .  .  .  .  .\n",
      ".  .  .  .  .  .  .\n",
      "O  .  .  X  .  .  .\n",
      "X  O  X  O  X  .  .\n",
      "\n",
      "0  1  2  3  4  5  6\n",
      ".  .  .  .  .  .  .\n",
      ".  .  .  .  .  .  .\n",
      ".  .  .  .  .  .  .\n",
      ".  .  .  .  .  .  .\n",
      "O  .  .  X  O  .  .\n",
      "X  O  X  O  X  .  .\n",
      "\n",
      "0  1  2  3  4  5  6\n",
      ".  .  .  .  .  .  .\n",
      ".  .  .  .  .  .  .\n",
      ".  .  .  .  .  .  .\n",
      "X  .  .  .  .  .  .\n",
      "O  .  .  X  O  .  .\n",
      "X  O  X  O  X  .  .\n",
      "\n",
      "0  1  2  3  4  5  6\n",
      ".  .  .  .  .  .  .\n",
      ".  .  .  .  .  .  .\n",
      ".  .  .  .  .  .  .\n",
      "X  .  .  .  .  .  .\n",
      "O  O  .  X  O  .  .\n",
      "X  O  X  O  X  .  .\n",
      "\n",
      "0  1  2  3  4  5  6\n",
      ".  .  .  .  .  .  .\n",
      ".  .  .  .  .  .  .\n",
      ".  .  .  .  .  .  .\n",
      "X  .  .  .  .  .  .\n",
      "O  O  X  X  O  .  .\n",
      "X  O  X  O  X  .  .\n",
      "\n",
      "0  1  2  3  4  5  6\n",
      ".  .  .  .  .  .  .\n",
      ".  .  .  .  .  .  .\n",
      ".  .  .  .  .  .  .\n",
      "X  .  .  .  .  .  .\n",
      "O  O  X  X  O  .  .\n",
      "X  O  X  O  X  O  .\n",
      "\n",
      "0  1  2  3  4  5  6\n",
      ".  .  .  .  .  .  .\n",
      ".  .  .  .  .  .  .\n",
      "X  .  .  .  .  .  .\n",
      "X  .  .  .  .  .  .\n",
      "O  O  X  X  O  .  .\n",
      "X  O  X  O  X  O  .\n",
      "\n",
      "0  1  2  3  4  5  6\n",
      ".  .  .  .  .  .  .\n",
      ".  .  .  .  .  .  .\n",
      "X  .  .  .  .  .  .\n",
      "X  O  .  .  .  .  .\n",
      "O  O  X  X  O  .  .\n",
      "X  O  X  O  X  O  .\n",
      "\n",
      "0  1  2  3  4  5  6\n",
      ".  .  .  .  .  .  .\n",
      ".  .  .  .  .  .  .\n",
      "X  .  .  .  .  .  .\n",
      "X  O  .  .  X  .  .\n",
      "O  O  X  X  O  .  .\n",
      "X  O  X  O  X  O  .\n",
      "\n",
      "0  1  2  3  4  5  6\n",
      ".  .  .  .  .  .  .\n",
      ".  .  .  .  .  .  .\n",
      "X  O  .  .  .  .  .\n",
      "X  O  .  .  X  .  .\n",
      "O  O  X  X  O  .  .\n",
      "X  O  X  O  X  O  .\n",
      "\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from copy import deepcopy\n",
    "from typing import Sequence\n",
    "\n",
    "NONE = '.'\n",
    "MAX = 'X'\n",
    "MIN = 'O'\n",
    "COLS = 7\n",
    "ROWS = 6\n",
    "N_WIN = 4\n",
    "\n",
    "\n",
    "class ArrayState:\n",
    "    def __init__(self, board, heights, n_moves):\n",
    "        self.board = board\n",
    "        self.heights = heights\n",
    "        self.n_moves = n_moves\n",
    "\n",
    "    @staticmethod\n",
    "    def init():\n",
    "        board = [[NONE] * ROWS for _ in range(COLS)]\n",
    "        return ArrayState(board, [0] * COLS, 0)\n",
    "\n",
    "\n",
    "def result(state: ArrayState, action: int) -> ArrayState:\n",
    "    \"\"\"Insert in the given column.\"\"\"\n",
    "    assert 0 <= action < COLS, \"action must be a column number\"\n",
    "\n",
    "    if state.heights[action] >= ROWS:\n",
    "        raise Exception('Column is full')\n",
    "\n",
    "    player = MAX if state.n_moves % 2 == 0 else MIN\n",
    "\n",
    "    board = deepcopy(state.board)\n",
    "    board[action][ROWS - state.heights[action] - 1] = player\n",
    "\n",
    "    heights = deepcopy(state.heights)\n",
    "    heights[action] += 1\n",
    "\n",
    "    return ArrayState(board, heights, state.n_moves + 1)\n",
    "\n",
    "\n",
    "def actions(state: ArrayState) -> Sequence[int]:\n",
    "    return [i for i in range(COLS) if state.heights[i] < ROWS]\n",
    "\n",
    "\n",
    "def branch_states(state: ArrayState) -> Sequence[ArrayState]:\n",
    "    \"\"\"get all reachable states from the current state:\n",
    "        useful for MCTS\n",
    "    \"\"\"\n",
    "    return [result(state, a) for a in actions(state)]\n",
    "    \n",
    "\n",
    "def utility(state: ArrayState) -> float:\n",
    "    \"\"\"Get the winner on the current board.\"\"\"\n",
    "\n",
    "    board = state.board\n",
    "\n",
    "    def diagonalsPos():\n",
    "        \"\"\"Get positive diagonals, going from bottom-left to top-right.\"\"\"\n",
    "        for di in ([(j, i - j) for j in range(COLS)] for i in range(COLS + ROWS - 1)):\n",
    "            yield [board[i][j] for i, j in di if i >= 0 and j >= 0 and i < COLS and j < ROWS]\n",
    "\n",
    "    def diagonalsNeg():\n",
    "        \"\"\"Get negative diagonals, going from top-left to bottom-right.\"\"\"\n",
    "        for di in ([(j, i - COLS + j + 1) for j in range(COLS)] for i in range(COLS + ROWS - 1)):\n",
    "            yield [board[i][j] for i, j in di if i >= 0 and j >= 0 and i < COLS and j < ROWS]\n",
    "\n",
    "    lines = board + \\\n",
    "            list(zip(*board)) + \\\n",
    "            list(diagonalsNeg()) + \\\n",
    "            list(diagonalsPos())\n",
    "\n",
    "    max_win = MAX * N_WIN\n",
    "    min_win = MIN * N_WIN\n",
    "    for line in lines:\n",
    "        str_line = \"\".join(line)\n",
    "        if max_win in str_line:\n",
    "            return 1\n",
    "        elif min_win in str_line:\n",
    "            return -1\n",
    "    return 0\n",
    "\n",
    "\n",
    "def terminal_test(state: ArrayState) -> bool:\n",
    "    return state.n_moves >= COLS * ROWS or utility(state) != 0\n",
    "\n",
    "\n",
    "def printBoard(state: ArrayState):\n",
    "    board = state.board\n",
    "    \"\"\"Print the board.\"\"\"\n",
    "    print('  '.join(map(str, range(COLS))))\n",
    "    for y in range(ROWS):\n",
    "        print('  '.join(str(board[x][y]) for x in range(COLS)))\n",
    "    print()\n",
    "\n",
    "\n",
    "\n",
    "s = ArrayState.init()\n",
    "while not terminal_test(s):\n",
    "    a = random.choice(actions(s))\n",
    "    s = result(s, a)\n",
    "    printBoard(s)\n",
    "print(utility(s))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rljSjxl4unxn"
   },
   "source": [
    "The last number 0, -1 or 1 is the utility or score of the game. 0 means it was a draw, 1 means MAX player won and -1 means MIN player won."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UUUpbYYJu6Zr"
   },
   "source": [
    "### Exercise 1 (Transfer code from the previous exercise)\n",
    "\n",
    "Modify the code so that you can play manually as the MIN player against the random AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from copy import deepcopy\n",
    "from typing import Sequence\n",
    "\n",
    "NONE = '.'\n",
    "MAX = 'X'\n",
    "MIN = 'O'\n",
    "COLS = 7\n",
    "ROWS = 6\n",
    "N_WIN = 4\n",
    "\n",
    "\n",
    "class ArrayState:\n",
    "    def __init__(self, board, heights, n_moves):\n",
    "        self.board = board\n",
    "        self.heights = heights\n",
    "        self.n_moves = n_moves\n",
    "\n",
    "    @staticmethod\n",
    "    def init():\n",
    "        board = [[NONE] * ROWS for _ in range(COLS)]\n",
    "        return ArrayState(board, [0] * COLS, 0)\n",
    "\n",
    "\n",
    "def result(state: ArrayState, action: int) -> ArrayState:\n",
    "    \"\"\"Insert in the given column.\"\"\"\n",
    "    assert 0 <= action < COLS, \"action must be a column number\"\n",
    "\n",
    "    if state.heights[action] >= ROWS:\n",
    "        raise Exception('Column is full')\n",
    "\n",
    "    player = MAX if state.n_moves % 2 == 0 else MIN\n",
    "\n",
    "    board = deepcopy(state.board)\n",
    "    board[action][ROWS - state.heights[action] - 1] = player\n",
    "\n",
    "    heights = deepcopy(state.heights)\n",
    "    heights[action] += 1\n",
    "\n",
    "    return ArrayState(board, heights, state.n_moves + 1)\n",
    "\n",
    "\n",
    "def actions(state: ArrayState) -> Sequence[int]:\n",
    "    return [i for i in range(COLS) if state.heights[i] < ROWS]\n",
    "\n",
    "def random_branch_state(state: ArrayState) -> ArrayState:\n",
    "    \"\"\" get a random state reachable from the current state \"\"\"\n",
    "    return result(state, random.choice(actions(state)))\n",
    "\n",
    "def branch_states(state: ArrayState) -> Sequence[ArrayState]:\n",
    "    \"\"\"get all reachable states from the current state:\n",
    "        useful for MCTS\n",
    "    \"\"\"\n",
    "    return [result(state, a) for a in actions(state)]\n",
    "    \n",
    "\n",
    "def utility(state: ArrayState) -> float:\n",
    "    \"\"\"Get the winner on the current board.\"\"\"\n",
    "\n",
    "    board = state.board\n",
    "\n",
    "    def diagonalsPos():\n",
    "        \"\"\"Get positive diagonals, going from bottom-left to top-right.\"\"\"\n",
    "        for di in ([(j, i - j) for j in range(COLS)] for i in range(COLS + ROWS - 1)):\n",
    "            yield [board[i][j] for i, j in di if i >= 0 and j >= 0 and i < COLS and j < ROWS]\n",
    "\n",
    "    def diagonalsNeg():\n",
    "        \"\"\"Get negative diagonals, going from top-left to bottom-right.\"\"\"\n",
    "        for di in ([(j, i - COLS + j + 1) for j in range(COLS)] for i in range(COLS + ROWS - 1)):\n",
    "            yield [board[i][j] for i, j in di if i >= 0 and j >= 0 and i < COLS and j < ROWS]\n",
    "\n",
    "    lines = board + \\\n",
    "            list(zip(*board)) + \\\n",
    "            list(diagonalsNeg()) + \\\n",
    "            list(diagonalsPos())\n",
    "\n",
    "    max_win = MAX * N_WIN\n",
    "    min_win = MIN * N_WIN\n",
    "    for line in lines:\n",
    "        str_line = \"\".join(line)\n",
    "        if max_win in str_line:\n",
    "            return 1\n",
    "        elif min_win in str_line:\n",
    "            return -1\n",
    "    return 0\n",
    "\n",
    "\n",
    "def terminal_test(state: ArrayState) -> bool:\n",
    "    return state.n_moves >= COLS * ROWS or utility(state) != 0\n",
    "\n",
    "\n",
    "def printBoard(state: ArrayState):\n",
    "    board = state.board\n",
    "    \"\"\"Print the board.\"\"\"\n",
    "    print('  '.join(map(str, range(COLS))))\n",
    "    for y in range(ROWS):\n",
    "        print('  '.join(str(board[x][y]) for x in range(COLS)))\n",
    "    print()\n",
    "\n",
    "\n",
    "\n",
    "s = ArrayState.init()\n",
    "while not terminal_test(s):\n",
    "    if s.n_moves % 2 == 1:\n",
    "        print(\"Player turn. Select a column (0-6):\")\n",
    "        a = input()\n",
    "    else: \n",
    "        a = random.choice(actions(s))\n",
    "    s = result(s, int(a))\n",
    "    printBoard(s)\n",
    "print(utility(s))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OrpAOYa-vbR6"
   },
   "source": [
    "### Exercise 2\n",
    "Implement the standard MCTS algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from collections import defaultdict\n",
    "import math\n",
    "\n",
    "\n",
    "class MCTS:\n",
    "    \"Monte Carlo tree searcher.\"\n",
    "\n",
    "    def __init__(self, exploration_weight=1):\n",
    "        self.rewards = defaultdict(int)\n",
    "        self.visitCounts = defaultdict(int)\n",
    "        self.children = dict()\n",
    "        self.explorationWeight = exploration_weight\n",
    "\n",
    "    def choose(self, state : ArrayState) -> ArrayState:\n",
    "        if terminal_test(state):\n",
    "            raise RuntimeError(\"Choose called on terminal state\")\n",
    "\n",
    "        if state not in self.children:\n",
    "            return random_branch_state(state)\n",
    "\n",
    "        def score(i):\n",
    "            if self.visitCounts[i] == 0:\n",
    "                return float('-inf')\n",
    "            return self.rewards[i] / self.visitCounts[i]\n",
    "\n",
    "        return max(self.children[state], key=score)\n",
    "        \n",
    "\n",
    "    def do_rollout(self, state : ArrayState):\n",
    "        \"Train for one iteration.\"\n",
    "        path = self._select(state)\n",
    "        leaf = path[-1]\n",
    "        self._expand(leaf)\n",
    "        reward = self._simulate(leaf)\n",
    "        self._backpropagate(path, reward)\n",
    "        \n",
    "\n",
    "    def _select(self, state : ArrayState):\n",
    "        \"Find an unexplored descendent of the `state`\"\n",
    "        path = []\n",
    "        while True:\n",
    "            path.append(state)\n",
    "            if state not in self.children or not self.children[state]: # unexplored or terminal path\n",
    "                return path\n",
    "            unexplored = self.children[state] - self.children.keys()\n",
    "            if unexplored:\n",
    "                nextState = unexplored.pop()\n",
    "                path.append(nextState)\n",
    "                return path\n",
    "            state = self._uct_select(state) # go one layer deeper if no unexplored or terminal path is found\n",
    "            \n",
    "\n",
    "    def _expand(self, state : ArrayState):\n",
    "        \"Expand the `state` with all states reachable from it\"\n",
    "        if state in self.children:\n",
    "            return # This board state has already been expanded\n",
    "        self.children[state] = state.branch_states(state)\n",
    "\n",
    "\n",
    "    def _simulate(self, state : ArrayState, invert_reward = True):\n",
    "        \"Returns the reward for a random simulation (to completion) of the `state`\"\n",
    "        while True:\n",
    "            if terminal_test(state):\n",
    "                reward = utility(state)\n",
    "                return 1 - reward if invert_reward else reward\n",
    "            state = random_branch_state(state)\n",
    "            invert_reward = not invert_reward # Switch to the other player\n",
    "            \n",
    "\n",
    "    def _backpropagate(self, path, reward):\n",
    "        \"Send the reward back up to the ancestors of the leaf\"\n",
    "        for state in reversed(path):\n",
    "            self.visitCounts[state] += 1\n",
    "            self.rewards[state] += reward\n",
    "            reward = 1 - reward # A reward for player MAX is the inverse for player MIN\n",
    "        \n",
    "\n",
    "    def _uct_select(self, state : ArrayState):\n",
    "        \"Select a child of state, balancing exploration & exploitation\"\n",
    "        assert all(s in self.children for s in self.children[state]) # all children of this state have been expanded already\n",
    "\n",
    "        def uct(s):\n",
    "            \"Upper confidence bound for trees\"\n",
    "            return self.rewards[s] + self.visitCounts[s] + self.explorationWeight * math.sqrt(math.log(self.visitCounts[s]) / self.visitCounts[s])\n",
    "        \n",
    "        return max(self.children[state], key=uct)\n",
    "\n",
    "    def train_model(self, state : ArrayState, num_rollouts : int):\n",
    "        for _ in range(num_rollouts):\n",
    "            self.do_rollout(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "Implement the loop where you play against your MCTS agent. Either train the agent at each step while you play against it, or pretrain it with more rollouts and play agaist it after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Play against the MCTS agent\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Exercise 4\n",
    "\n",
    "Add move ordering. The middle columns are often \"better\" since there's more winning positions that contain them. Increase the probability to choose middle columns when randomly executing rollouts: [3,2,4,1,5,0,6]. See if your connect4 AI can beat you.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "enbI-o_Cw6Jw"
   },
   "source": [
    "### Exercise 5 - Optional\n",
    "\n",
    "Pit your MCTS agent against the one from the previous exercise.\n",
    "* Which one wins more often?\n",
    "* Which one takes more time to run per step once it is at a point that it can beat you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uqAPS8cFgVN-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "connect4.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "ecf5722fdaf1897a315d257d89d94520bfcaa453217d5becf09b39e73618b0de"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
